{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise de Risco de Crédito - NuBank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Risco de crédito está associado à possibilidade de um cliente não cumprir com as obrigações contratuais, como hipotecas, dívidas de cartão de crédito e outros tipos de empréstimos.\n",
    "\n",
    "Minimizar o risco de inadimplência é uma grande preocupação para instituições financeiras. Por esse motivo, bancos comerciais e de investimento, fundos de capital de risco, empresas de gestão de ativos e seguradoras, para citar alguns, estão cada vez mais contando com a tecnologia para prever quais clientes são mais propensos a não honrar com as suas dívidas.\n",
    "\n",
    "Modelos de Machine Learning têm ajudado essas empresas a melhorar a precisão de suas análises de risco de crédito, fornecendo um método científico para identificar devedores em potencial com antecedência.\n",
    "\n",
    "Neste projeto, construiremos um modelo para prever o risco de inadimplência do cliente para o Nubank, uma das maiores e importantes Fintechs brasileira."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelagem "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objetivo\n",
    "\n",
    "- Prever o risco de inadimplência de clientes usando modelos de aprendizado de máquina, incluindo Regressão Logística,XGBoost, LightGBM e CatBoost.\n",
    "\n",
    "- Problema: Identificar a possibilidade de clientes não cumprirem obrigações contratuais, como empréstimos e pagamentos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importação das Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation and visualization.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Modelling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix, roc_curve, precision_recall_curve\n",
    "import time\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "\n",
    "# Filter warnings.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importação do Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/acquisition_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualização dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ids</th>\n",
       "      <th>target_default</th>\n",
       "      <th>score_1</th>\n",
       "      <th>score_2</th>\n",
       "      <th>score_3</th>\n",
       "      <th>score_4</th>\n",
       "      <th>score_5</th>\n",
       "      <th>score_6</th>\n",
       "      <th>risk_rate</th>\n",
       "      <th>last_amount_borrowed</th>\n",
       "      <th>...</th>\n",
       "      <th>external_data_provider_fraud_score</th>\n",
       "      <th>lat_lon</th>\n",
       "      <th>marketing_channel</th>\n",
       "      <th>profile_phone_number</th>\n",
       "      <th>reported_income</th>\n",
       "      <th>shipping_state</th>\n",
       "      <th>shipping_zip_code</th>\n",
       "      <th>profile_tags</th>\n",
       "      <th>user_agent</th>\n",
       "      <th>target_fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>343b7e7b-2cf8-e508-b8fd-0a0285af30aa</td>\n",
       "      <td>False</td>\n",
       "      <td>1Rk8w4Ucd5yR3KcqZzLdow==</td>\n",
       "      <td>IOVu8au3ISbo6+zmfnYwMg==</td>\n",
       "      <td>350.0</td>\n",
       "      <td>101.800832</td>\n",
       "      <td>0.259555</td>\n",
       "      <td>108.427273</td>\n",
       "      <td>0.40</td>\n",
       "      <td>25033.92</td>\n",
       "      <td>...</td>\n",
       "      <td>645</td>\n",
       "      <td>(-29.151545708122246, -51.1386461804385)</td>\n",
       "      <td>Invite-email</td>\n",
       "      <td>514-9840782</td>\n",
       "      <td>57849.0</td>\n",
       "      <td>BR-MT</td>\n",
       "      <td>17528</td>\n",
       "      <td>{'tags': ['n19', 'n8']}</td>\n",
       "      <td>Mozilla/5.0 (Linux; Android 6.0.1; SGP771 Buil...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bc2c7502-bbad-0f8c-39c3-94e881967124</td>\n",
       "      <td>False</td>\n",
       "      <td>DGCQep2AE5QRkNCshIAlFQ==</td>\n",
       "      <td>SaamrHMo23l/3TwXOWgVzw==</td>\n",
       "      <td>370.0</td>\n",
       "      <td>97.062615</td>\n",
       "      <td>0.942655</td>\n",
       "      <td>92.002546</td>\n",
       "      <td>0.24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>243</td>\n",
       "      <td>(-19.687710705798963, -47.94151536525154)</td>\n",
       "      <td>Radio-commercial</td>\n",
       "      <td>251-3659293</td>\n",
       "      <td>4902.0</td>\n",
       "      <td>BR-RS</td>\n",
       "      <td>40933</td>\n",
       "      <td>{'tags': ['n6', 'n7', 'nim']}</td>\n",
       "      <td>Mozilla/5.0 (Linux; Android 5.0.2; SAMSUNG SM-...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    ids target_default  \\\n",
       "0  343b7e7b-2cf8-e508-b8fd-0a0285af30aa          False   \n",
       "1  bc2c7502-bbad-0f8c-39c3-94e881967124          False   \n",
       "\n",
       "                    score_1                   score_2  score_3     score_4  \\\n",
       "0  1Rk8w4Ucd5yR3KcqZzLdow==  IOVu8au3ISbo6+zmfnYwMg==    350.0  101.800832   \n",
       "1  DGCQep2AE5QRkNCshIAlFQ==  SaamrHMo23l/3TwXOWgVzw==    370.0   97.062615   \n",
       "\n",
       "    score_5     score_6  risk_rate  last_amount_borrowed  ...  \\\n",
       "0  0.259555  108.427273       0.40              25033.92  ...   \n",
       "1  0.942655   92.002546       0.24                   NaN  ...   \n",
       "\n",
       "   external_data_provider_fraud_score  \\\n",
       "0                                 645   \n",
       "1                                 243   \n",
       "\n",
       "                                     lat_lon marketing_channel  \\\n",
       "0   (-29.151545708122246, -51.1386461804385)      Invite-email   \n",
       "1  (-19.687710705798963, -47.94151536525154)  Radio-commercial   \n",
       "\n",
       "   profile_phone_number reported_income shipping_state shipping_zip_code  \\\n",
       "0           514-9840782         57849.0          BR-MT             17528   \n",
       "1           251-3659293          4902.0          BR-RS             40933   \n",
       "\n",
       "                    profile_tags  \\\n",
       "0        {'tags': ['n19', 'n8']}   \n",
       "1  {'tags': ['n6', 'n7', 'nim']}   \n",
       "\n",
       "                                          user_agent target_fraud  \n",
       "0  Mozilla/5.0 (Linux; Android 6.0.1; SGP771 Buil...          NaN  \n",
       "1  Mozilla/5.0 (Linux; Android 5.0.2; SAMSUNG SM-...          NaN  \n",
       "\n",
       "[2 rows x 43 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infos dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45000 entries, 0 to 44999\n",
      "Data columns (total 43 columns):\n",
      " #   Column                                            Non-Null Count  Dtype  \n",
      "---  ------                                            --------------  -----  \n",
      " 0   ids                                               45000 non-null  object \n",
      " 1   target_default                                    41741 non-null  object \n",
      " 2   score_1                                           44438 non-null  object \n",
      " 3   score_2                                           44438 non-null  object \n",
      " 4   score_3                                           44438 non-null  float64\n",
      " 5   score_4                                           45000 non-null  float64\n",
      " 6   score_5                                           45000 non-null  float64\n",
      " 7   score_6                                           45000 non-null  float64\n",
      " 8   risk_rate                                         44438 non-null  float64\n",
      " 9   last_amount_borrowed                              15044 non-null  float64\n",
      " 10  last_borrowed_in_months                           15044 non-null  float64\n",
      " 11  credit_limit                                      31200 non-null  float64\n",
      " 12  reason                                            44434 non-null  object \n",
      " 13  income                                            44438 non-null  float64\n",
      " 14  facebook_profile                                  40542 non-null  object \n",
      " 15  state                                             44438 non-null  object \n",
      " 16  zip                                               44438 non-null  object \n",
      " 17  channel                                           44438 non-null  object \n",
      " 18  job_name                                          41664 non-null  object \n",
      " 19  real_state                                        44438 non-null  object \n",
      " 20  ok_since                                          18455 non-null  float64\n",
      " 21  n_bankruptcies                                    44303 non-null  float64\n",
      " 22  n_defaulted_loans                                 44426 non-null  float64\n",
      " 23  n_accounts                                        44438 non-null  float64\n",
      " 24  n_issues                                          33456 non-null  float64\n",
      " 25  application_time_applied                          45000 non-null  object \n",
      " 26  application_time_in_funnel                        45000 non-null  int64  \n",
      " 27  email                                             45000 non-null  object \n",
      " 28  external_data_provider_credit_checks_last_2_year  22372 non-null  float64\n",
      " 29  external_data_provider_credit_checks_last_month   45000 non-null  int64  \n",
      " 30  external_data_provider_credit_checks_last_year    29876 non-null  float64\n",
      " 31  external_data_provider_email_seen_before          42767 non-null  float64\n",
      " 32  external_data_provider_first_name                 45000 non-null  object \n",
      " 33  external_data_provider_fraud_score                45000 non-null  int64  \n",
      " 34  lat_lon                                           43637 non-null  object \n",
      " 35  marketing_channel                                 41422 non-null  object \n",
      " 36  profile_phone_number                              45000 non-null  object \n",
      " 37  reported_income                                   45000 non-null  float64\n",
      " 38  shipping_state                                    45000 non-null  object \n",
      " 39  shipping_zip_code                                 45000 non-null  int64  \n",
      " 40  profile_tags                                      45000 non-null  object \n",
      " 41  user_agent                                        44278 non-null  object \n",
      " 42  target_fraud                                      1522 non-null   object \n",
      "dtypes: float64(18), int64(4), object(21)\n",
      "memory usage: 14.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Temos dados ausentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclusão das Variáveis não significativas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Seguindo como base os processos feitos na Análise Exploratória de Dados - EDA, vamos excluir logo de início as variáveis não relevantes para o projeto, seguido da variável **Shipping State** por não agregar até o momento nenhuma significância para o projeto. Não vejo valor na distribuição dos estados com relação as outras variáveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cópia do dataframe\n",
    "df2 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_columns = [\"ids\", \"score_1\", \"score_2\", \"score_4\", \"score_5\", \"score_6\",\"reason\", \"facebook_profile\", \"state\", \"zip\", \"channel\", \"job_name\", \"real_state\",\n",
    "                    \"email\", \"external_data_provider_first_name\", \"external_data_provider_email_seen_before\",\"lat_lon\", \"marketing_channel\",\n",
    "                    \"application_time_applied\", \"profile_phone_number\", \"application_time_in_funnel\",\"shipping_zip_code\", \"external_data_provider_fraud_score\",\n",
    "                    \"profile_tags\", \"user_agent\", \"shipping_state\",\"target_fraud\"]\n",
    "\n",
    "df2.drop(labels = exclude_columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alteração variável Target Default para Num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['target_default'] = df2['target_default'].map({False: 0, True: 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alteração da Variável credit_limit com valor 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A variável **credit_limit** possui um valor mínimo de 0.000000, isso não existe em instituições financeiras, é obrigatório liberar um valor X de crédito para o cliente. Portanto, este valor será substituído por NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['credit_limit'] = df2['credit_limit'].apply(lambda x: np.nan if x == 0 else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alteração da Variável reported_income com Valor Inf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A variável **reported_income** possui um valor máximo descrito como inf(infinito), nesse caso, vamos alterar para o tipo NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.replace([np.inf, -np.inf], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seguindo o que foi feito com as \"Perguntas de Negócio utilizando o Score 3\" na Análise Exploratória no eda.ipynb, que é o Score mais robusto para o projeto, vamos criar uma nova variável chamada Scores, onde vamos dividir os valores seguindo com base na descrição do Score anteriormente:\n",
    "\n",
    "O score brasileiro é geralmente dividido em faixas:\n",
    "\n",
    "- Baixo (0-300): Alto risco de inadimplência.\n",
    "- Médio (301-700): Risco moderado.\n",
    "- Alto (701-1000): Baixo risco de inadimplência.\n",
    "\n",
    "Então vamos ter uma variável chamada de \"score\" que será dividida com os valores dessa forma e vamos excluir as outras colunas de score para essa nova análise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores(score):\n",
    "    if score <= 300:\n",
    "        return 'baixo'\n",
    "    elif score >= 301 and score <= 700:\n",
    "        return 'medio'\n",
    "    else:\n",
    "        return 'alto'\n",
    "    \n",
    "df2['score'] = df2['score_3'].apply(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Exclusão da variável score_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.drop(columns=['score_3'], axis = 1, inplace = True)\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divisão dos dados em treino e teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Antes de iniciar as transformações e pré-processamentos dos dados, é necessário dividir o dataset em treino e teste, mas porque?\n",
    "    - Porque precisamos evitar o \"Data Leakage\". Data Leakage ocorre quando informações do conjunto de dados de teste ou validação vazam para o conjunto de treinamento durante o pré-processamento ou modelagem, ou quando informaçõpes do target vazam para as features. Nessas situações, o que vai acontecer é que você vai ver um modelo muito bom, mas isso será ilusório, pois o seu modelo \"roubou\" para ter o resultado bom.\n",
    "\n",
    "- Referências sobre Data Leakage: \n",
    "    - https://www.linkedin.com/company/universidade-dos-dados/posts/?feedView=all\n",
    "    - https://www.casadocodigo.com.br/products/livro-escd\n",
    "    - https://estatsite.com.br/2020/12/12/data-leakage-o-erro-que-ate-os-grandes-cometem/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividindo os dados primeiro\n",
    "\n",
    "X = df2.drop(columns=['target_default'], axis = 1)\t\n",
    "y = df2['target_default'].copy()                                                                                                                                                                                                                                                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando o One Hot Encoding\n",
    "X = pd.get_dummies(X, columns=['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>risk_rate</th>\n",
       "      <th>last_amount_borrowed</th>\n",
       "      <th>last_borrowed_in_months</th>\n",
       "      <th>credit_limit</th>\n",
       "      <th>income</th>\n",
       "      <th>ok_since</th>\n",
       "      <th>n_bankruptcies</th>\n",
       "      <th>n_defaulted_loans</th>\n",
       "      <th>n_accounts</th>\n",
       "      <th>n_issues</th>\n",
       "      <th>external_data_provider_credit_checks_last_2_year</th>\n",
       "      <th>external_data_provider_credit_checks_last_month</th>\n",
       "      <th>external_data_provider_credit_checks_last_year</th>\n",
       "      <th>reported_income</th>\n",
       "      <th>score_alto</th>\n",
       "      <th>score_baixo</th>\n",
       "      <th>score_medio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25180</th>\n",
       "      <td>0.17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32451.0</td>\n",
       "      <td>95035.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20125.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12555</th>\n",
       "      <td>0.23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86026.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24460.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29153</th>\n",
       "      <td>0.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45042.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>144703.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23838</th>\n",
       "      <td>0.28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74039.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>186114.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35686</th>\n",
       "      <td>0.22</td>\n",
       "      <td>6029.18</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55026.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98152.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       risk_rate  last_amount_borrowed  last_borrowed_in_months  credit_limit  \\\n",
       "25180       0.17                   NaN                      NaN       32451.0   \n",
       "12555       0.23                   NaN                      NaN           NaN   \n",
       "29153       0.40                   NaN                      NaN           NaN   \n",
       "23838       0.28                   NaN                      NaN           NaN   \n",
       "35686       0.22               6029.18                     36.0           NaN   \n",
       "\n",
       "         income  ok_since  n_bankruptcies  n_defaulted_loans  n_accounts  \\\n",
       "25180  95035.02       NaN             0.0                0.0         7.0   \n",
       "12555  86026.89       NaN             0.0                0.0         8.0   \n",
       "29153  45042.92       NaN             0.0                0.0         3.0   \n",
       "23838  74039.33       NaN             0.0                0.0         7.0   \n",
       "35686  55026.98       NaN             0.0                0.0         9.0   \n",
       "\n",
       "       n_issues  external_data_provider_credit_checks_last_2_year  \\\n",
       "25180       7.0                                               NaN   \n",
       "12555       NaN                                               0.0   \n",
       "29153       NaN                                               NaN   \n",
       "23838       NaN                                               0.0   \n",
       "35686       NaN                                               NaN   \n",
       "\n",
       "       external_data_provider_credit_checks_last_month  \\\n",
       "25180                                                0   \n",
       "12555                                                1   \n",
       "29153                                                2   \n",
       "23838                                                2   \n",
       "35686                                                0   \n",
       "\n",
       "       external_data_provider_credit_checks_last_year  reported_income  \\\n",
       "25180                                             0.0          20125.0   \n",
       "12555                                             NaN          24460.0   \n",
       "29153                                             1.0         144703.0   \n",
       "23838                                             1.0         186114.0   \n",
       "35686                                             NaN          98152.0   \n",
       "\n",
       "       score_alto  score_baixo  score_medio  \n",
       "25180       False        False         True  \n",
       "12555       False        False         True  \n",
       "29153       False         True        False  \n",
       "23838       False         True        False  \n",
       "35686       False         True        False  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré-Processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Preencher valores ausentes em X_train e X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preencher valores ausentes em X_train e X_test com a média de X_train\n",
    "X_train.fillna(X_train.mean(), inplace=True)\n",
    "X_test.fillna(X_train.mean(), inplace=True)  # Usar a média de X_train para X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Preencher valores ausentes em y_train e y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preencher valores ausentes em y_train e y_test com a mediana\n",
    "y_train.fillna(y_train.median(), inplace=True)\n",
    "y_test.fillna(y_train.median(), inplace=True)  # Usar a mediana de y_train para y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = X_train.select_dtypes('number').columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('std_scaler', StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('std_scaler', numerical_pipeline, numerical_features)\n",
    "    ], remainder=\"passthrough\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_prepared = preprocessor.fit_transform(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função de avaliação para fornecer todas as métricas após o treinamento do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(true, predicted):\n",
    "    mae = mean_absolute_error(true, predicted)\n",
    "    mse = mean_squared_error(true, predicted)\n",
    "    rmse = np.sqrt(mean_squared_error(true, predicted))\n",
    "    r2_square = r2_score(true, predicted)\n",
    "    return mae, rmse, r2_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression() results: \n",
      "--------------------------------------------------\n",
      "Training score: 0.5\n",
      "Average validation score: 0.6042375852567284\n",
      "Standard deviation: 0.006494068734945479\n",
      "Training time: 0.02837 seconds\n",
      "\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...) results: \n",
      "--------------------------------------------------\n",
      "Training score: 0.5465762872874316\n",
      "Average validation score: 0.5729452332304513\n",
      "Standard deviation: 0.005895054707272672\n",
      "Training time: 0.30102 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'XGBoost': XGBClassifier()\n",
    "}\n",
    "model_list = []\n",
    "r2_list =[]\n",
    "\n",
    "models_val_scores = dict()\n",
    "models_train_scores = dict()\n",
    "\n",
    "n_folds = 5\n",
    "stratified_kfold = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    model.fit(X_train_prepared, y_train) \n",
    "\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "\n",
    "\n",
    "    y_train_pred = model.predict(X_train_prepared)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    y_train_pred = model.predict(X_train_prepared)\n",
    "    train_score = roc_auc_score(y_train, y_train_pred)\n",
    "\n",
    "    val_scores = cross_val_score(model, X_train_prepared, y_train, scoring='roc_auc', cv=stratified_kfold)\n",
    "    avg_val_score = val_scores.mean()\n",
    "    val_score_std = val_scores.std()\n",
    "\n",
    "    models_val_scores[model] = avg_val_score\n",
    "    models_train_scores[model] = train_score\n",
    "\n",
    "    model_list.append(list(models.keys())[i])\n",
    "\n",
    "    print(f'{model} results: ')\n",
    "    print('-'*50)\n",
    "    print(f'Training score: {train_score}')\n",
    "    print(f'Average validation score: {avg_val_score}')\n",
    "    print(f'Standard deviation: {val_score_std}')\n",
    "    print(f'Training time: {round(training_time, 5)} seconds')\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-likelihood: -4.7922\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def log_likelihood_bernoulli(data, p):\n",
    "    \"\"\"\n",
    "    Calcula o log-likelihood para uma distribuição de Bernoulli.\n",
    "    \n",
    "    Parâmetros:\n",
    "    - data: array-like, os valores observados (0 ou 1).\n",
    "    - p: float, a probabilidade de sucesso (0 < p < 1).\n",
    "    \n",
    "    Retorna:\n",
    "    - log-likelihood: float.\n",
    "    \"\"\"\n",
    "    if p <= 0 or p >= 1:\n",
    "        raise ValueError(\"A probabilidade 'p' deve estar entre 0 e 1 (exclusivo).\")\n",
    "    \n",
    "    data = np.asarray(data)  # Converte os dados para um array do NumPy\n",
    "    ll = np.sum(data * np.log(p) + (1 - data) * np.log(1 - p))\n",
    "    return ll\n",
    "\n",
    "# Exemplo de uso\n",
    "data = [1, 0, 1, 1, 0, 0, 1]  # Dados observados (amostra)\n",
    "p = 0.6  # Probabilidade de sucesso\n",
    "ll = log_likelihood_bernoulli(data, p)\n",
    "print(f\"Log-likelihood: {ll:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
