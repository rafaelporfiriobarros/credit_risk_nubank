{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise de Risco de Crédito - NuBank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Risco de crédito está associado à possibilidade de um cliente não cumprir com as obrigações contratuais, como hipotecas, dívidas de cartão de crédito e outros tipos de empréstimos.\n",
    "\n",
    "Minimizar o risco de inadimplência é uma grande preocupação para instituições financeiras. Por esse motivo, bancos comerciais e de investimento, fundos de capital de risco, empresas de gestão de ativos e seguradoras, para citar alguns, estão cada vez mais contando com a tecnologia para prever quais clientes são mais propensos a não honrar com as suas dívidas.\n",
    "\n",
    "Modelos de Machine Learning têm ajudado essas empresas a melhorar a precisão de suas análises de risco de crédito, fornecendo um método científico para identificar devedores em potencial com antecedência.\n",
    "\n",
    "Neste projeto, construiremos um modelo para prever o risco de inadimplência do cliente para o Nubank, uma das maiores e importantes Fintechs brasileira."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelagem "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objetivo\n",
    "\n",
    "- Prever o risco de inadimplência de clientes usando modelos de aprendizado de máquina, incluindo Regressão Logística,XGBoost, LightGBM e CatBoost.\n",
    "\n",
    "- Problema: Identificar a possibilidade de clientes não cumprirem obrigações contratuais, como empréstimos e pagamentos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importação das Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation and visualization.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Modelling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "\n",
    "# Filter warnings.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importação do Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/acquisition_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualização dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ids</th>\n",
       "      <th>target_default</th>\n",
       "      <th>score_1</th>\n",
       "      <th>score_2</th>\n",
       "      <th>score_3</th>\n",
       "      <th>score_4</th>\n",
       "      <th>score_5</th>\n",
       "      <th>score_6</th>\n",
       "      <th>risk_rate</th>\n",
       "      <th>last_amount_borrowed</th>\n",
       "      <th>...</th>\n",
       "      <th>external_data_provider_fraud_score</th>\n",
       "      <th>lat_lon</th>\n",
       "      <th>marketing_channel</th>\n",
       "      <th>profile_phone_number</th>\n",
       "      <th>reported_income</th>\n",
       "      <th>shipping_state</th>\n",
       "      <th>shipping_zip_code</th>\n",
       "      <th>profile_tags</th>\n",
       "      <th>user_agent</th>\n",
       "      <th>target_fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>343b7e7b-2cf8-e508-b8fd-0a0285af30aa</td>\n",
       "      <td>False</td>\n",
       "      <td>1Rk8w4Ucd5yR3KcqZzLdow==</td>\n",
       "      <td>IOVu8au3ISbo6+zmfnYwMg==</td>\n",
       "      <td>350.0</td>\n",
       "      <td>101.800832</td>\n",
       "      <td>0.259555</td>\n",
       "      <td>108.427273</td>\n",
       "      <td>0.40</td>\n",
       "      <td>25033.92</td>\n",
       "      <td>...</td>\n",
       "      <td>645</td>\n",
       "      <td>(-29.151545708122246, -51.1386461804385)</td>\n",
       "      <td>Invite-email</td>\n",
       "      <td>514-9840782</td>\n",
       "      <td>57849.0</td>\n",
       "      <td>BR-MT</td>\n",
       "      <td>17528</td>\n",
       "      <td>{'tags': ['n19', 'n8']}</td>\n",
       "      <td>Mozilla/5.0 (Linux; Android 6.0.1; SGP771 Buil...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bc2c7502-bbad-0f8c-39c3-94e881967124</td>\n",
       "      <td>False</td>\n",
       "      <td>DGCQep2AE5QRkNCshIAlFQ==</td>\n",
       "      <td>SaamrHMo23l/3TwXOWgVzw==</td>\n",
       "      <td>370.0</td>\n",
       "      <td>97.062615</td>\n",
       "      <td>0.942655</td>\n",
       "      <td>92.002546</td>\n",
       "      <td>0.24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>243</td>\n",
       "      <td>(-19.687710705798963, -47.94151536525154)</td>\n",
       "      <td>Radio-commercial</td>\n",
       "      <td>251-3659293</td>\n",
       "      <td>4902.0</td>\n",
       "      <td>BR-RS</td>\n",
       "      <td>40933</td>\n",
       "      <td>{'tags': ['n6', 'n7', 'nim']}</td>\n",
       "      <td>Mozilla/5.0 (Linux; Android 5.0.2; SAMSUNG SM-...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    ids target_default  \\\n",
       "0  343b7e7b-2cf8-e508-b8fd-0a0285af30aa          False   \n",
       "1  bc2c7502-bbad-0f8c-39c3-94e881967124          False   \n",
       "\n",
       "                    score_1                   score_2  score_3     score_4  \\\n",
       "0  1Rk8w4Ucd5yR3KcqZzLdow==  IOVu8au3ISbo6+zmfnYwMg==    350.0  101.800832   \n",
       "1  DGCQep2AE5QRkNCshIAlFQ==  SaamrHMo23l/3TwXOWgVzw==    370.0   97.062615   \n",
       "\n",
       "    score_5     score_6  risk_rate  last_amount_borrowed  ...  \\\n",
       "0  0.259555  108.427273       0.40              25033.92  ...   \n",
       "1  0.942655   92.002546       0.24                   NaN  ...   \n",
       "\n",
       "   external_data_provider_fraud_score  \\\n",
       "0                                 645   \n",
       "1                                 243   \n",
       "\n",
       "                                     lat_lon marketing_channel  \\\n",
       "0   (-29.151545708122246, -51.1386461804385)      Invite-email   \n",
       "1  (-19.687710705798963, -47.94151536525154)  Radio-commercial   \n",
       "\n",
       "   profile_phone_number reported_income shipping_state shipping_zip_code  \\\n",
       "0           514-9840782         57849.0          BR-MT             17528   \n",
       "1           251-3659293          4902.0          BR-RS             40933   \n",
       "\n",
       "                    profile_tags  \\\n",
       "0        {'tags': ['n19', 'n8']}   \n",
       "1  {'tags': ['n6', 'n7', 'nim']}   \n",
       "\n",
       "                                          user_agent target_fraud  \n",
       "0  Mozilla/5.0 (Linux; Android 6.0.1; SGP771 Buil...          NaN  \n",
       "1  Mozilla/5.0 (Linux; Android 5.0.2; SAMSUNG SM-...          NaN  \n",
       "\n",
       "[2 rows x 43 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infos dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45000 entries, 0 to 44999\n",
      "Data columns (total 43 columns):\n",
      " #   Column                                            Non-Null Count  Dtype  \n",
      "---  ------                                            --------------  -----  \n",
      " 0   ids                                               45000 non-null  object \n",
      " 1   target_default                                    41741 non-null  object \n",
      " 2   score_1                                           44438 non-null  object \n",
      " 3   score_2                                           44438 non-null  object \n",
      " 4   score_3                                           44438 non-null  float64\n",
      " 5   score_4                                           45000 non-null  float64\n",
      " 6   score_5                                           45000 non-null  float64\n",
      " 7   score_6                                           45000 non-null  float64\n",
      " 8   risk_rate                                         44438 non-null  float64\n",
      " 9   last_amount_borrowed                              15044 non-null  float64\n",
      " 10  last_borrowed_in_months                           15044 non-null  float64\n",
      " 11  credit_limit                                      31200 non-null  float64\n",
      " 12  reason                                            44434 non-null  object \n",
      " 13  income                                            44438 non-null  float64\n",
      " 14  facebook_profile                                  40542 non-null  object \n",
      " 15  state                                             44438 non-null  object \n",
      " 16  zip                                               44438 non-null  object \n",
      " 17  channel                                           44438 non-null  object \n",
      " 18  job_name                                          41664 non-null  object \n",
      " 19  real_state                                        44438 non-null  object \n",
      " 20  ok_since                                          18455 non-null  float64\n",
      " 21  n_bankruptcies                                    44303 non-null  float64\n",
      " 22  n_defaulted_loans                                 44426 non-null  float64\n",
      " 23  n_accounts                                        44438 non-null  float64\n",
      " 24  n_issues                                          33456 non-null  float64\n",
      " 25  application_time_applied                          45000 non-null  object \n",
      " 26  application_time_in_funnel                        45000 non-null  int64  \n",
      " 27  email                                             45000 non-null  object \n",
      " 28  external_data_provider_credit_checks_last_2_year  22372 non-null  float64\n",
      " 29  external_data_provider_credit_checks_last_month   45000 non-null  int64  \n",
      " 30  external_data_provider_credit_checks_last_year    29876 non-null  float64\n",
      " 31  external_data_provider_email_seen_before          42767 non-null  float64\n",
      " 32  external_data_provider_first_name                 45000 non-null  object \n",
      " 33  external_data_provider_fraud_score                45000 non-null  int64  \n",
      " 34  lat_lon                                           43637 non-null  object \n",
      " 35  marketing_channel                                 41422 non-null  object \n",
      " 36  profile_phone_number                              45000 non-null  object \n",
      " 37  reported_income                                   45000 non-null  float64\n",
      " 38  shipping_state                                    45000 non-null  object \n",
      " 39  shipping_zip_code                                 45000 non-null  int64  \n",
      " 40  profile_tags                                      45000 non-null  object \n",
      " 41  user_agent                                        44278 non-null  object \n",
      " 42  target_fraud                                      1522 non-null   object \n",
      "dtypes: float64(18), int64(4), object(21)\n",
      "memory usage: 14.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Temos dados ausentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclusão das Variáveis não significativas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Seguindo como base os processos feitos na Análise Exploratória de Dados - EDA, vamos excluir logo de início as variáveis não relevantes para o projeto, seguido da variável **Shipping State** por não agregar até o momento nenhuma significância para o projeto. Não vejo valor na distribuição dos estados com relação as outras variáveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cópia do dataframe\n",
    "df2 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_columns = [\"ids\", \"score_1\", \"score_2\", \"score_4\", \"score_5\", \"score_6\",\"reason\", \"facebook_profile\", \"state\", \"zip\", \"channel\", \"job_name\", \"real_state\",\n",
    "                    \"email\", \"external_data_provider_first_name\", \"external_data_provider_email_seen_before\",\"lat_lon\", \"marketing_channel\",\n",
    "                    \"application_time_applied\", \"profile_phone_number\", \"application_time_in_funnel\",\"shipping_zip_code\", \"external_data_provider_fraud_score\",\n",
    "                    \"profile_tags\", \"user_agent\", \"shipping_state\",\"target_fraud\"]\n",
    "\n",
    "df2.drop(labels = exclude_columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alteração variável Target Default para Num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['target_default'] = df2['target_default'].map({False: 0, True: 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alteração da Variável credit_limit com valor 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A variável **credit_limit** possui um valor mínimo de 0.000000, isso não existe em instituições financeiras, é obrigatório liberar um valor X de crédito para o cliente. Portanto, este valor será substituído por NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['credit_limit'] = df2['credit_limit'].apply(lambda x: np.nan if x == 0 else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alteração da Variável reported_income com Valor Inf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A variável **reported_income** possui um valor máximo descrito como inf(infinito), nesse caso, vamos alterar para o tipo NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.replace([np.inf, -np.inf], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seguindo o que foi feito com as \"Perguntas de Negócio utilizando o Score 3\" na Análise Exploratória no eda.ipynb, que é o Score mais robusto para o projeto, vamos criar uma nova variável chamada Scores, onde vamos dividir os valores seguindo com base na descrição do Score anteriormente:\n",
    "\n",
    "O score brasileiro é geralmente dividido em faixas:\n",
    "\n",
    "- Baixo (0-300): Alto risco de inadimplência.\n",
    "- Médio (301-700): Risco moderado.\n",
    "- Alto (701-1000): Baixo risco de inadimplência.\n",
    "\n",
    "Então vamos ter uma variável chamada de \"score\" que será dividida com os valores dessa forma e vamos excluir as outras colunas de score para essa nova análise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores(score):\n",
    "    if score <= 300:\n",
    "        return 'baixo'\n",
    "    elif score >= 301 and score <= 700:\n",
    "        return 'medio'\n",
    "    else:\n",
    "        return 'alto'\n",
    "    \n",
    "df2['score'] = df2['score_3'].apply(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Exclusão da variável score_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.drop(columns=['score_3'], axis = 1, inplace = True)\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divisão dos dados em treino e teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Antes de iniciar as transformações e pré-processamentos dos dados, é necessário dividir o dataset em treino e teste, mas porque?\n",
    "    - Porque precisamos evitar o \"Data Leakage\". Data Leakage ocorre quando informações do conjunto de dados de teste ou validação vazam para o conjunto de treinamento durante o pré-processamento ou modelagem, ou quando informaçõpes do target vazam para as features. Nessas situações, o que vai acontecer é que você vai ver um modelo muito bom, mas isso será ilusório, pois o seu modelo \"roubou\" para ter o resultado bom.\n",
    "\n",
    "- Referências sobre Data Leakage: \n",
    "    - https://www.linkedin.com/company/universidade-dos-dados/posts/?feedView=all\n",
    "    - https://www.casadocodigo.com.br/products/livro-escd\n",
    "    - https://estatsite.com.br/2020/12/12/data-leakage-o-erro-que-ate-os-grandes-cometem/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividindo os dados primeiro\n",
    "\n",
    "X = df2.drop(columns=['target_default'], axis = 1)\t\n",
    "y = df2['target_default'].copy()                                                                                                                                                                                                                                                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando o One Hot Encoding\n",
    "X = pd.get_dummies(X, columns=['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré-Processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Preencher valores ausentes em X_train e X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preencher valores ausentes em X_train e X_test com a média de X_train\n",
    "X_train.fillna(X_train.mean(), inplace=True)\n",
    "X_test.fillna(X_train.mean(), inplace=True)  # Usar a média de X_train para X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Preencher valores ausentes em y_train e y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preencher valores ausentes em y_train e y_test com a mediana\n",
    "y_train.fillna(y_train.median(), inplace=True)\n",
    "y_test.fillna(y_train.median(), inplace=True)  # Usar a mediana de y_train para y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = X_train.select_dtypes('number').columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('std_scaler', StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('std_scaler', numerical_pipeline, numerical_features)\n",
    "    ], remainder=\"passthrough\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_prepared = preprocessor.fit_transform(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função de avaliação para fornecer todas as métricas após o treinamento do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(true, predicted):\n",
    "    mae = mean_absolute_error(true, predicted)\n",
    "    mse = mean_squared_error(true, predicted)\n",
    "    rmse = np.sqrt(mean_squared_error(true, predicted))\n",
    "    r2_square = r2_score(true, predicted)\n",
    "    return mae, rmse, r2_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.3865\n",
      "- Mean Absolute Error: 0.1494\n",
      "- R2 Score: -0.1757\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.3774\n",
      "- Mean Absolute Error: 0.1424\n",
      "- R2 Score: -0.1661\n",
      "===================================\n",
      "\n",
      "\n",
      "XGBoost\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.3684\n",
      "- Mean Absolute Error: 0.1358\n",
      "- R2 Score: -0.0681\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.3774\n",
      "- Mean Absolute Error: 0.1424\n",
      "- R2 Score: -0.1661\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'XGBoost': XGBClassifier()\n",
    "}\n",
    "model_list = []\n",
    "r2_list =[]\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train_prepared, y_train) # Train model\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train_prepared)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate Train and Test dataset\n",
    "    model_train_mae , model_train_rmse, model_train_r2 = evaluate_model(y_train, y_train_pred)\n",
    "\n",
    "    model_test_mae , model_test_rmse, model_test_r2 = evaluate_model(y_test, y_test_pred)\n",
    "\n",
    "    \n",
    "    print(list(models.keys())[i])\n",
    "    model_list.append(list(models.keys())[i])\n",
    "    \n",
    "    print('Model performance for Training set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_train_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_train_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_train_r2))\n",
    "\n",
    "    print('----------------------------------')\n",
    "    \n",
    "    print('Model performance for Test set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_test_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_test_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_test_r2))\n",
    "    r2_list.append(model_test_r2)\n",
    "    \n",
    "    print('='*35)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
